{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(x):\n",
    "    #2x^2 + 3x - 5\n",
    "    return 2 * th.pow(x, 2) - 3 * x - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleX(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x = nn.Parameter(th.FloatTensor([np.random.random() * 100]))\n",
    "    \n",
    "    def forward(self, f):\n",
    "        return th.sum(f(self.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3027.9001\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SingleX()\n",
    "print(model(criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 1 is 3027.900146484375\n",
      "Loss at iteration 2 is 1086.1240234375\n",
      "Loss at iteration 3 is 387.0845947265625\n",
      "Loss at iteration 4 is 135.43048095703125\n",
      "Loss at iteration 5 is 44.8349609375\n",
      "Loss at iteration 6 is 12.220584869384766\n",
      "Loss at iteration 7 is 0.47941017150878906\n",
      "Loss at iteration 8 is -3.7474122047424316\n",
      "Loss at iteration 9 is -5.269068717956543\n",
      "Loss at iteration 10 is -5.816864490509033\n",
      "Loss at iteration 11 is -6.014071464538574\n",
      "Loss at iteration 12 is -6.085065841674805\n",
      "Loss at iteration 13 is -6.110623836517334\n",
      "Loss at iteration 14 is -6.119824409484863\n",
      "Loss at iteration 15 is -6.1231369972229\n",
      "Loss at iteration 16 is -6.124329090118408\n",
      "Loss at iteration 17 is -6.124758720397949\n",
      "Loss at iteration 18 is -6.124913215637207\n",
      "Loss at iteration 19 is -6.124968528747559\n",
      "Loss at iteration 20 is -6.124988555908203\n",
      "Loss at iteration 21 is -6.124995708465576\n",
      "Loss at iteration 22 is -6.124998569488525\n",
      "Loss at iteration 23 is -6.124999523162842\n",
      "Loss at iteration 24 is -6.125\n",
      "Loss at iteration 25 is -6.125\n",
      "Loss at iteration 26 is -6.125\n",
      "Loss at iteration 27 is -6.125\n",
      "Loss at iteration 28 is -6.125\n",
      "Loss at iteration 29 is -6.125\n",
      "Loss at iteration 30 is -6.125\n",
      "Loss at iteration 31 is -6.125\n",
      "Loss at iteration 32 is -6.125\n",
      "Loss at iteration 33 is -6.125\n",
      "Loss at iteration 34 is -6.125\n",
      "Loss at iteration 35 is -6.125\n",
      "Loss at iteration 36 is -6.125\n",
      "Loss at iteration 37 is -6.125\n",
      "Loss at iteration 38 is -6.125\n",
      "Loss at iteration 39 is -6.125\n",
      "Loss at iteration 40 is -6.125\n",
      "Loss at iteration 41 is -6.125\n",
      "Loss at iteration 42 is -6.125\n",
      "Loss at iteration 43 is -6.125\n",
      "Loss at iteration 44 is -6.125\n",
      "Loss at iteration 45 is -6.125\n",
      "Loss at iteration 46 is -6.125\n",
      "Loss at iteration 47 is -6.125\n",
      "Loss at iteration 48 is -6.125\n",
      "Loss at iteration 49 is -6.125\n",
      "Loss at iteration 50 is -6.125\n",
      "Loss at iteration 51 is -6.125\n",
      "Loss at iteration 52 is -6.125\n",
      "Loss at iteration 53 is -6.125\n",
      "Loss at iteration 54 is -6.125\n",
      "Loss at iteration 55 is -6.125\n",
      "Loss at iteration 56 is -6.125\n",
      "Loss at iteration 57 is -6.125\n",
      "Loss at iteration 58 is -6.125\n",
      "Loss at iteration 59 is -6.125\n",
      "Loss at iteration 60 is -6.125\n",
      "Loss at iteration 61 is -6.125\n",
      "Loss at iteration 62 is -6.125\n",
      "Loss at iteration 63 is -6.125\n",
      "Loss at iteration 64 is -6.125\n",
      "Loss at iteration 65 is -6.125\n",
      "Loss at iteration 66 is -6.125\n",
      "Loss at iteration 67 is -6.125\n",
      "Loss at iteration 68 is -6.125\n",
      "Loss at iteration 69 is -6.125\n",
      "Loss at iteration 70 is -6.125\n",
      "Loss at iteration 71 is -6.125\n",
      "Loss at iteration 72 is -6.125\n",
      "Loss at iteration 73 is -6.125\n",
      "Loss at iteration 74 is -6.125\n",
      "Loss at iteration 75 is -6.125\n",
      "Loss at iteration 76 is -6.125\n",
      "Loss at iteration 77 is -6.125\n",
      "Loss at iteration 78 is -6.125\n",
      "Loss at iteration 79 is -6.125\n",
      "Loss at iteration 80 is -6.125\n",
      "Loss at iteration 81 is -6.125\n",
      "Loss at iteration 82 is -6.125\n",
      "Loss at iteration 83 is -6.125\n",
      "Loss at iteration 84 is -6.125\n",
      "Loss at iteration 85 is -6.125\n",
      "Loss at iteration 86 is -6.125\n",
      "Loss at iteration 87 is -6.125\n",
      "Loss at iteration 88 is -6.125\n",
      "Loss at iteration 89 is -6.125\n",
      "Loss at iteration 90 is -6.125\n",
      "Loss at iteration 91 is -6.125\n",
      "Loss at iteration 92 is -6.125\n",
      "Loss at iteration 93 is -6.125\n",
      "Loss at iteration 94 is -6.125\n",
      "Loss at iteration 95 is -6.125\n",
      "Loss at iteration 96 is -6.125\n",
      "Loss at iteration 97 is -6.125\n",
      "Loss at iteration 98 is -6.125\n",
      "Loss at iteration 99 is -6.125\n",
      "Loss at iteration 100 is -6.125\n"
     ]
    }
   ],
   "source": [
    "for it in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = model(criterion)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Loss at iteration {it + 1} is {loss.data[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       " 0.7500\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
